## for 4 gpus in a single node
runai training mpi submit nccl-test \
  -p nccl-benchmarking \
  -i nvcr.io/nvidia/pytorch:25.08-py3 \
  -g 4 \
  --workers 1 \
  --slots-per-worker 4 \
  --node-pools default \
  --master-command "bash" \
  --master-args "-c 'sleep 1d'" \
  -- bash -c 'sleep 1d'